{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from sklearn import datasets\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "rootgrp1 = Dataset(\"../data/cal_cams_gfas.nc\", \"r\", format=\"NETCDF4\")\n",
    "frpfire = rootgrp1.variables[\"frpfire\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278.91125783710294\n",
      "279.06073267677107\n",
      "95117.98874326676\n",
      "0.00020309033959300428\n",
      "-0.3951265188014619\n",
      "1.457960204363011\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "rootgrp2 = Dataset(\"../data/cal_era5_2008.nc\", \"r\", format=\"NETCDF4\")\n",
    "swvl1 = rootgrp2.variables[\"swvl1\"]\n",
    "d2m = rootgrp2.variables[\"d2m\"]\n",
    "t2m = rootgrp2.variables[\"t2m\"]\n",
    "sp = rootgrp2.variables[\"sp\"]\n",
    "tp = rootgrp2.variables[\"tp\"]\n",
    "u10 = rootgrp2.variables[\"u10\"]\n",
    "v10 = rootgrp2.variables[\"v10\"]\n",
    "lai_lv = rootgrp2.variables[\"lai_lv\"]\n",
    "print(d2m[10][10][10])\n",
    "print(t2m[10][10][10])\n",
    "print(sp[10][10][10])\n",
    "print(tp[10][10][10])\n",
    "print(u10[10][10][10])\n",
    "print(v10[10][10][10])\n",
    "print(lai_lv[10][10][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3723365,)\n",
      "(3723365,)\n"
     ]
    }
   ],
   "source": [
    "x1_vals = np.array(swvl1[0:365][:][:]).reshape(-1)\n",
    "x2_vals = np.array(d2m[0:365][:][:]).reshape(-1)\n",
    "x3_vals = np.array(t2m[0:365][:][:]).reshape(-1)\n",
    "x4_vals = np.array(sp[0:365][:][:]).reshape(-1)\n",
    "x5_vals = np.array(tp[0:365][:][:]).reshape(-1)\n",
    "x6_vals = np.array(u10[0:365][:][:]).reshape(-1)\n",
    "x7_vals = np.array(v10[0:365][:][:]).reshape(-1)\n",
    "x8_vals = np.array(lai_lv[0:365][:][:]).reshape(-1)\n",
    "y_vals = np.array(frpfire[0:365][:][:]).reshape(-1)\n",
    "print(y_vals.shape)\n",
    "print(x1_vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "learning_rate = 0.05\n",
    "batch_size = 101*101\n",
    "x_data = tf.placeholder(shape=[None, n], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "A = tf.Variable(tf.zeros(shape=[n,1]))\n",
    "b = tf.Variable(tf.zeros(shape=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = tf.add(tf.matmul(x_data, A), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y_target - model_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "my_opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 3.2360725e-22\n",
      "Loss = 0.14494717\n",
      "Loss = 7835390.5\n",
      "Loss = 469254970000000.0\n",
      "Loss = 2.7661435e+22\n",
      "Loss = 1.5587406e+30\n",
      "Loss = inf\n",
      "Loss = inf\n",
      "Loss = inf\n",
      "Loss = inf\n",
      "Loss = inf\n",
      "Loss = inf\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n",
      "Loss = nan\n"
     ]
    }
   ],
   "source": [
    "loss_vec = []\n",
    "for i in range(365):\n",
    "    index = 101*101\n",
    "    x = x1_vals[i*index:(i+1)*index].reshape(index)\n",
    "    x1 = np.append(x, x2_vals[i*index:(i+1)*index].reshape(index))\n",
    "        #x = np.append(x, x3_vals[i][:][:].reshape(101*101))\n",
    "        #x = np.append(x,x4_vals[i][:][:].reshape(101*101))\n",
    "        #x = np.append(x, x5_vals[i][:][:].reshape(101*101))\n",
    "        #x = np.append(x, x6_vals[i][:][:].reshape(101*101))\n",
    "        #x = np.append(x, x7_vals[i][:][:].reshape(101*101))\n",
    "        #x = np.append(x, x8_vals[i][:][:].reshape(101*101))\n",
    "    x2 = x1.reshape(index,n)\n",
    "    y  = y_vals[i*index:(i+1)*index].reshape(index,1)\n",
    "    sess.run(train_step, feed_dict={x_data: x2, y_target:y})\n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: x2,  y_target:y})\n",
    "    loss_vec.append(temp_loss)\n",
    "    if (i)%1==0:\n",
    "        print('Loss = ''' + str(temp_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
